# Module 2: Loan Default Prediction Engine
**Mesin Prediksi Risiko Gagal Bayar Berbasis Machine Learning**

---

## ğŸ“Œ Tujuan Module

Module 2 bertanggung jawab untuk:
1. **Memprediksi probabilitas default** pinjaman berdasarkan karakteristik peminjam dan pinjaman
2. **Mengklasifikasikan risk category** (Low/Medium/High)
3. **Menjelaskan prediksi** menggunakan feature importance dan SHAP values
4. **Mengintegrasikan financial health metrics** dari Module 1 untuk prediksi yang lebih akurat

---

## ğŸ—ï¸ Arsitektur Module 2

```
Input: Loan Request + Financial Metrics (from Module 1)
    â”œâ”€â”€ Loan Data:
    â”‚   â”œâ”€â”€ jumlah_pinjaman
    â”‚   â”œâ”€â”€ durasi_hari
    â”‚   â”œâ”€â”€ jenis_pinjaman
    â”‚   â”œâ”€â”€ provinsi
    â”‚   â”œâ”€â”€ status_peminjam (Baru/Lama)
    â”‚   â”œâ”€â”€ sektor_usaha
    â”‚   â”œâ”€â”€ pendidikan
    â”‚   â””â”€â”€ jenis_jaminan
    â”‚
    â””â”€â”€ Financial Metrics (from Module 1):
        â”œâ”€â”€ debt_to_income_ratio
        â”œâ”€â”€ expense_ratio
        â”œâ”€â”€ savings_ratio
        â””â”€â”€ disposable_income_ratio

         â†“

[1] FEATURE ASSEMBLY
    â””â”€â”€ Combine & Engineer Features
        â€¢ Clean & impute missing values
        â€¢ Engineer derived features
        â€¢ Aggregate statistics
        â€¢ Ensure feature schema consistency

         â†“

[2] MODEL INFERENCE
    â””â”€â”€ LightGBM Gradient Boosting Model
        â€¢ Frozen pre-trained model
        â€¢ 30+ features input
        â€¢ Output: Default probability (0.0 - 1.0)

         â†“

[3] EXPLAINER
    â””â”€â”€ Generate Explanations
        â€¢ SHAP values for feature contributions
        â€¢ Risk category classification
        â€¢ Confidence scoring
        â€¢ Top risk & protective factors

         â†“

Output: Prediction + Explanation
    â”œâ”€â”€ default_prediction: 0 or 1
    â”œâ”€â”€ default_probability: 0.0 to 1.0
    â”œâ”€â”€ risk_category: "low" / "medium" / "high"
    â”œâ”€â”€ confidence: "low" / "medium" / "high"
    â””â”€â”€ explanation:
        â”œâ”€â”€ feature_contributions
        â”œâ”€â”€ top_risk_factors
        â””â”€â”€ top_protective_factors
```

---

## ğŸ”§ Component 1: Feature Assembly

### Prinsip Desain
- **Stateless Transformation:** No side effects, reproducible
- **Consistent with Training:** Feature engineering HARUS sama dengan training pipeline
- **Handle Missing Values:** Imputation strategy yang sama dengan training
- **No Data Leakage:** Hanya gunakan informasi yang tersedia saat prediction time

### Step 1: Data Cleaning

**Masalah yang Sering Ditemui:**
1. **Negative Duration:** `durasi_hari = -90`
   - Fix: Ambil absolute value
   - Rationale: Kemungkinan input error, maksudnya 90 hari

2. **Future Dates:** `tanggal_pencairan = "2025-12-25"` (saat sistem berjalan di 2024)
   - Fix: Kurangi 1 tahun
   - Rationale: Input error tahun

3. **Missing Tanggal:** Tidak ada `tanggal_pencairan`
   - Fix: Gunakan tanggal saat ini
   - Rationale: Default ke current date

### Step 2: Imputation Strategy

**Prinsip Imputation:**
- Gunakan **median ratio dari training data**, BUKAN median absolut
- Mengapa? Karena scale-invariant dan lebih robust

**Contoh Imputation:**

**âŒ Pendekatan Naive (Median Absolut):**
```
Missing total_pengembalian â†’ Impute dengan median = 30,000,000
```
Problem: User yang pinjam 5 juta vs 500 juta mendapat imputation yang sama!

**âœ… Pendekatan Sistem Ini (Median Ratio):**
```
Dari training data: total_pengembalian / jumlah_pinjaman â‰ˆ 1.15 (median)

Missing total_pengembalian:
â†’ Impute dengan: jumlah_pinjaman Ã— 1.15

User A: Pinjam 5 juta â†’ Impute total_pengembalian = 5.75 juta
User B: Pinjam 500 juta â†’ Impute total_pengembalian = 575 juta
```

**Imputation Rules:**
```
MEDIAN_RETURN_RATIO = 1.15  (dari training data)
MEDIAN_LENDER_RATIO = 0.95  (dari training data)
MEDIAN_DURATION = 90        (dari training data)

IF total_pengembalian is missing:
    total_pengembalian = jumlah_pinjaman Ã— 1.15

IF porsi_pengembalian_lender is missing:
    porsi_pengembalian_lender = total_pengembalian Ã— 0.95

IF durasi_hari is missing:
    durasi_hari = 90

IF categorical fields missing:
    Fill with "Unknown"
```

### Step 3: Feature Engineering

**Derived Features yang Dihasilkan:**

#### 1. Temporal Features
**Mengapa Penting?**
Seasonality dan time trends dapat mempengaruhi default rate.

```
From tanggal_pencairan:
â”œâ”€â”€ month: Bulan pencairan (1-12)
â”œâ”€â”€ quarter: Quarter (1-4)
â”œâ”€â”€ day_of_week: Hari dalam minggu (0-6)
â””â”€â”€ is_month_end: Boolean (hari 25-31)
```

**Insight:**
- Pinjaman yang dicairkan akhir bulan mungkin lebih risky (cashflow tight)
- Seasonality: Default rate mungkin berbeda per quarter

#### 2. Financial Ratios
```
daily_payment = total_pengembalian / durasi_hari
payment_burden = daily_payment / (income / 30)  # Assuming monthly income
```

**Insight:**
- `payment_burden` mengukur berapa persen dari daily income yang harus dialokasikan untuk cicilan
- Semakin tinggi, semakin berat beban cicilan

#### 3. Loan Characteristics
```
loan_intensity = jumlah_pinjaman / durasi_hari
```

**Insight:**
- Pinjaman short-term dengan amount besar memiliki risk profile berbeda
- High loan_intensity = high daily payment pressure

#### 4. Aggregation Features (Statistical Encoding)

**Mengapa Diperlukan?**
Categorical features seperti `provinsi` memiliki banyak unique values. Jika di-encode dengan one-hot, akan menghasilkan ratusan features (curse of dimensionality).

**Pendekatan Traditional (One-Hot Encoding):**
```
provinsi:
â”œâ”€â”€ provinsi_DKI_Jakarta: 1/0
â”œâ”€â”€ provinsi_Jawa_Barat: 1/0
â”œâ”€â”€ provinsi_Jawa_Timur: 1/0
â””â”€â”€ ... (34 columns untuk 34 provinsi)
```
Problem: Sparse matrix, overfitting, tidak generalize

**âœ… Pendekatan Sistem Ini (Aggregation/Target Encoding):**
```
Dari training data, hitung rata-rata default rate per provinsi:

provinsi_avg_default_rate:
â”œâ”€â”€ DKI Jakarta: 0.08  (8% default rate di DKI Jakarta)
â”œâ”€â”€ Jawa Barat: 0.12   (12% default rate di Jawa Barat)
â””â”€â”€ Papua: 0.15        (15% default rate di Papua)

Untuk prediction:
IF provinsi = "DKI Jakarta":
    provinsi_default_rate_feature = 0.08
```

**Keunggulan:**
- âœ… Single numeric feature, bukan puluhan binary features
- âœ… Capture regional risk differences
- âœ… Handle unseen categories ("Unknown" â†’ use global average)

**Aggregation Features yang Dibuat:**
```
1. provinsi_avg_default_rate
2. jenis_pinjaman_avg_default_rate
3. sektor_usaha_avg_default_rate
4. pendidikan_avg_default_rate
5. jenis_jaminan_avg_default_rate
```

#### 5. Integration dengan Module 1 (Financial Health Features)

**Critical Integration Point:**

Module 2 menerima financial metrics dari Module 1:
```
financial_metrics (from Module 1):
â”œâ”€â”€ debt_to_income_ratio
â”œâ”€â”€ expense_ratio
â”œâ”€â”€ savings_ratio
â””â”€â”€ disposable_income_ratio
```

**Ditambahkan ke feature set:**
```
features_df['debt_to_income_ratio'] = financial_metrics['debt_to_income_ratio']
features_df['expense_ratio'] = financial_metrics['expense_ratio']
...
```

**Mengapa Ini Powerful?**

Tanpa Module 1:
- Model hanya melihat loan characteristics (amount, duration, type)
- Tidak tahu financial capacity borrower

Dengan Module 1:
- Model tahu DTI ratio, expense pattern, savings adequacy
- Bisa assess affordability, bukan hanya loan characteristics
- **Contoh:** Pinjaman 50 juta untuk user dengan DTI 2.0 vs DTI 8.0 akan diprediksi berbeda

### Step 4: Feature Schema Consistency

**Critical Requirement:**
Feature order dan naming HARUS persis sama dengan training.

**Mengapa?**
Model di-train dengan feature order tertentu:
```
Training: [jumlah_pinjaman, durasi_hari, dti_ratio, ...]
```

Jika prediction menggunakan order berbeda:
```
Prediction: [durasi_hari, jumlah_pinjaman, dti_ratio, ...]
```
â†’ Model akan salah interpretasi features â†’ Prediksi kacau!

**Solusi:**
Sistem menyimpan expected feature schema dan melakukan validation:
```
expected_features = [
    'jumlah_pinjaman',
    'durasi_hari',
    'debt_to_income_ratio',
    ...
]

# Reorder features to match expected schema
features_df = features_df[expected_features]
```

---

## ğŸ¤– Component 2: Model Inference (LightGBM)

### Mengapa LightGBM?

**Algoritma Alternatives:**
| Algorithm | Pros | Cons |
|-----------|------|------|
| Logistic Regression | Simple, explainable | Linear, can't capture complex patterns |
| Random Forest | Robust, handles non-linearity | Slower, larger model size |
| XGBoost | High accuracy | Computationally expensive |
| **LightGBM** | Fast, accurate, handles categorical, memory efficient | Needs careful tuning |

**Keunggulan LightGBM untuk Use Case Ini:**
1. **Gradient Boosting:** Iteratively improve predictions
2. **Leaf-wise Growth:** More accurate than level-wise
3. **Categorical Support:** Native handling of categorical features
4. **Fast Inference:** Critical untuk production
5. **Feature Importance:** Built-in explainability

### Bagaimana LightGBM Bekerja?

**Konsep Dasar: Ensemble of Decision Trees**

**âŒ Single Decision Tree (Overfitting):**
```
Tree 1:
    IF jumlah_pinjaman > 50M THEN default = 1
    ELSE default = 0
```
Problem: Terlalu simplistic, overfitting

**âœ… Gradient Boosting (Ensemble of Weak Trees):**
```
Tree 1: Makes initial prediction
    â†’ Error = Actual - Prediction

Tree 2: Learns to predict the error from Tree 1
    â†’ New Prediction = Tree1 + Tree2

Tree 3: Learns to predict remaining error
    â†’ New Prediction = Tree1 + Tree2 + Tree3

... (100-1000 trees)

Final Prediction = Î£(all trees)
```

**Mengapa Powerful?**
- Setiap tree fokus pada memperbaiki error dari tree sebelumnya
- Kombinasi weak learners â†’ Strong learner
- Capture non-linear relationships

### Model Architecture

**Training Configuration:**
```
num_trees: ~100-500 (optimal dari tuning)
max_depth: 6-10 (prevent overfitting)
learning_rate: 0.01-0.1 (step size untuk learning)
num_leaves: 31-127 (complexity control)
```

**Features Used (~30+ features):**
```
Loan Characteristics:
â”œâ”€â”€ jumlah_pinjaman
â”œâ”€â”€ durasi_hari
â”œâ”€â”€ daily_payment
â”œâ”€â”€ loan_intensity
â”œâ”€â”€ month, quarter, day_of_week

Categorical (Encoded):
â”œâ”€â”€ provinsi_default_rate
â”œâ”€â”€ jenis_pinjaman_default_rate
â”œâ”€â”€ sektor_usaha_default_rate
â”œâ”€â”€ pendidikan_default_rate
â”œâ”€â”€ jenis_jaminan_default_rate

Financial Health (from Module 1):
â”œâ”€â”€ debt_to_income_ratio
â”œâ”€â”€ expense_ratio
â”œâ”€â”€ savings_ratio
â””â”€â”€ disposable_income_ratio
```

### Model Output

**Probability Output:**
```
Model outputs: Raw probability (0.0 to 1.0)

Example:
â””â”€â”€ 0.15 â†’ 15% probability of default
```

**Classification Threshold:**
```
IF probability >= 0.5:
    prediction = 1 (Default)
ELSE:
    prediction = 0 (Non-Default)
```

**Risk Category:**
```
IF probability < 0.15:
    risk_category = "low"
ELIF probability < 0.35:
    risk_category = "medium"
ELSE:
    risk_category = "high"
```

---

## ğŸ“Š Component 3: Explainer (SHAP-based)

### Mengapa Perlu Explainability?

**Black Box Problem:**
```
User: "Mengapa default probability saya 25%?"
Black Box Model: "Karena model mengatakan begitu."
User: "???"
```

**With Explainability:**
```
User: "Mengapa default probability saya 25%?"
Explainer:
â”œâ”€â”€ DTI ratio tinggi (4.5) â†’ +8% contribution to default risk
â”œâ”€â”€ Loan amount besar (100M) â†’ +5% contribution
â”œâ”€â”€ Duration pendek (30 hari) â†’ +4% contribution
â”œâ”€â”€ Savings ratio rendah (1.0) â†’ +3% contribution
â””â”€â”€ Provinsi risk sedang â†’ +2% contribution
    Total Impact: Baseline 5% + 22% = 27% â‰ˆ 25%
```

### SHAP (SHapley Additive exPlanations)

**Konsep Dasar:**
SHAP values menjelaskan kontribusi setiap feature terhadap prediksi.

**Formula (Simplified):**
```
Prediction = Base Value + Î£(SHAP values untuk setiap feature)

Example:
Base Value (Average default rate) = 0.05 (5%)

SHAP values:
â”œâ”€â”€ debt_to_income_ratio: +0.08
â”œâ”€â”€ jumlah_pinjaman: +0.05
â”œâ”€â”€ savings_ratio: -0.02 (protective factor)
â””â”€â”€ ...

Final Prediction = 0.05 + 0.08 + 0.05 - 0.02 + ... = 0.25 (25%)
```

**Interpretasi SHAP Values:**
- **Positive SHAP value:** Feature ini MENINGKATKAN risk
- **Negative SHAP value:** Feature ini MENURUNKAN risk
- **Magnitude:** Seberapa besar kontribusinya

### Feature Contributions Breakdown

**Output dari Explainer:**

```json
{
    "prediction_probability": 0.25,
    "baseline_probability": 0.05,
    "feature_contributions": [
        {
            "feature": "debt_to_income_ratio",
            "value": 4.5,
            "importance": 0.15,
            "contribution": 0.08,
            "impact": "increases_risk"
        },
        {
            "feature": "savings_ratio",
            "value": 1.2,
            "importance": 0.08,
            "contribution": -0.02,
            "impact": "decreases_risk"
        },
        ...
    ],
    "top_risk_factors": [
        "High DTI ratio (4.5x income)",
        "Large loan amount (100M)",
        "Short duration (30 days)"
    ],
    "top_protective_factors": [
        "Good expense control (60% expense ratio)",
        "Positive cashflow"
    ]
}
```

### Confidence Scoring

**Bagaimana Confidence Dihitung?**

```
Prediction probability distribution:

High Confidence:
â”œâ”€â”€ probability very low (< 0.10) â†’ Clearly low risk
â””â”€â”€ probability very high (> 0.70) â†’ Clearly high risk

Medium Confidence:
â”œâ”€â”€ 0.10 - 0.30 or 0.50 - 0.70

Low Confidence:
â””â”€â”€ 0.30 - 0.50 (Borderline, uncertain)
```

**Mengapa Penting?**
- Borderline cases memerlukan human review
- High confidence predictions bisa di-automate
- Transparent risk management

---

## ğŸ¯ Keunggulan Machine Learning di Module 2

### 1. Capture Complex Patterns

**Rule-Based Tidak Bisa:**
```
"High risk IF jumlah_pinjaman > 50M"
```
Problem: Pinjaman 100M untuk orang dengan income 1M vs 100M sangat berbeda!

**ML Bisa:**
```
Model learns: Risk = f(jumlah_pinjaman, income, dti_ratio, interactions, ...)

Capture non-linear interactions:
â”œâ”€â”€ Large loan + Low DTI â†’ Low risk
â”œâ”€â”€ Large loan + High DTI â†’ High risk
â”œâ”€â”€ Large loan + Short duration â†’ Very high risk
â””â”€â”€ Large loan + Short duration + High savings â†’ Medium risk
```

### 2. Learn from Historical Data

**Rule-Based:**
- Manually define: "DTI > 6.0 = High Risk"
- Based on domain knowledge

**ML:**
- Automatically discovers: "DTI > 6.0 correlates with 35% default rate"
- Plus: Discovers interactions you didn't know
- Example: "High DTI in Jakarta less risky than in remote areas"

### 3. Adaptive Feature Importance

**Different Features Matter for Different Users:**

For high-income users:
- Savings ratio â†’ More important
- Loan amount â†’ Less important

For low-income users:
- DTI ratio â†’ Most critical
- Duration â†’ Very important

ML automatically learns these nuances.

### 4. Probability Output (Not Binary)

**Rule-Based:**
```
Risk = "High" or "Low" (Binary)
```

**ML:**
```
Default Probability = 0.25 (25%)
â†’ Can set different thresholds untuk different risk appetites
â†’ Can price loans based on risk (higher rate for higher risk)
```

---

## âš ï¸ Limitations & Mitigations

### Limitation 1: Black Box Nature
**Problem:** Model kompleks sulit dijelaskan

**Mitigation:**
- âœ… SHAP explainability
- âœ… Feature importance ranking
- âœ… Individual prediction breakdowns

### Limitation 2: Training Data Dependency
**Problem:** Model hanya sebaik training data-nya

**Mitigation:**
- âœ… Careful data quality checks
- âœ… Outlier detection & handling
- âœ… Bias detection & mitigation

### Limitation 3: Concept Drift
**Problem:** Patterns berubah seiring waktu

**Mitigation:**
- âœ… Model monitoring (track prediction accuracy)
- âœ… Periodic retraining schedule
- âœ… Alert system untuk performance degradation

### Limitation 4: Overfitting Risk
**Problem:** Model too complex, memorize training data

**Mitigation:**
- âœ… Cross-validation during training
- âœ… Regularization (max_depth, min_samples_leaf)
- âœ… Out-of-sample testing

---

## ğŸ”„ Integration dengan Module Lain

### Input dari Module 1
```
Module 1 Output â†’ Module 2 Input:
â”œâ”€â”€ debt_to_income_ratio â†’ Critical feature
â”œâ”€â”€ expense_ratio â†’ Affordability indicator
â”œâ”€â”€ savings_ratio â†’ Buffer capacity
â””â”€â”€ disposable_income_ratio â†’ Cashflow indicator
```

**Impact:**
Tanpa Module 1 metrics, model accuracy drop ~10-15%!

### Output ke Module 3
```
Module 2 Output â†’ Module 3 Input:
â”œâ”€â”€ default_probability â†’ Risk assessment
â”œâ”€â”€ explanation â†’ Root cause identification
â””â”€â”€ feature_contributions â†’ Scenario impact analysis
```

---

## ğŸ”¬ Model Performance Metrics

### Classification Metrics

**1. AUC-ROC (Area Under Curve - Receiver Operating Characteristic):**
- Measures: Ability untuk distinguish default vs non-default
- Target: > 0.80 (good), > 0.85 (excellent)
- Interpretation: 0.85 means 85% probability model ranks a random defaulter higher than random non-defaulter

**2. Precision & Recall Trade-off:**
```
Precision = TP / (TP + FP)
â””â”€â”€ "Among predicted defaults, how many actually defaulted?"

Recall = TP / (TP + FN)
â””â”€â”€ "Among actual defaults, how many did we catch?"
```

**Business Impact:**
- High Precision: Few false alarms (don't reject good borrowers)
- High Recall: Catch most defaulters (minimize losses)
- Trade-off: Adjust threshold based on business priority

**3. Calibration:**
- Predicted 20% default â†’ Actually observe ~20% default?
- Important untuk probability interpretation

---

## ğŸ¯ Model vs Rules: Complementary Roles

**Module 1 (Rules):**
- âœ… Transparent baseline
- âœ… Explainable thresholds
- âœ… No training data needed
- âŒ Can't capture complexity

**Module 2 (ML):**
- âœ… Capture complex patterns
- âœ… Learn from data
- âœ… Probabilistic output
- âŒ Black box (mitigated with SHAP)

**Together:**
- Module 1 provides explainable health assessment
- Module 2 provides accurate risk prediction
- Module 3 combines both untuk actionable insights

---

## ğŸ“ Summary

**Module 2 adalah prediction engine dari sistem:**

âœ… **Strengths:**
- High accuracy dari gradient boosting
- Capture complex non-linear patterns
- Probabilistic output (risk quantification)
- SHAP-based explainability
- Integration dengan Module 1 untuk comprehensive assessment

âš ï¸ **Limitations:**
- Requires quality training data
- Black box nature (mitigated)
- Potential for concept drift
- Computational overhead

ğŸ¯ **Role dalam Sistem:**
- Core prediction engine
- Risk quantification (probability)
- Pattern discovery yang tidak bisa ditangkap rules
- Foundation untuk Module 3 recommendations

**Next:** Module 3 akan mengintegrasikan output dari Module 1 & 2 untuk generate actionable insights dan recommendations.
